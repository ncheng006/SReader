{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "\n",
    "from google.cloud import speech\n",
    "import pyaudio\n",
    "from six.moves import queue\n",
    "\n",
    "# Audio recording parameters\n",
    "STREAMING_LIMIT = 240000  # 4 minutes\n",
    "SAMPLE_RATE = 16000\n",
    "CHUNK_SIZE = int(SAMPLE_RATE / 10)  # 100ms\n",
    "\n",
    "RED = \"\\033[0;31m\"\n",
    "GREEN = \"\\033[0;32m\"\n",
    "YELLOW = \"\\033[0;33m\"\n",
    "\n",
    "\n",
    "def get_current_time():\n",
    "    \"\"\"Return Current Time in MS.\"\"\"\n",
    "\n",
    "    return int(round(time.time() * 1000))\n",
    "\n",
    "\n",
    "class ResumableMicrophoneStream:\n",
    "    \"\"\"Opens a recording stream as a generator yielding the audio chunks.\"\"\"\n",
    "\n",
    "    def __init__(self, rate, chunk_size):\n",
    "        self._rate = rate\n",
    "        self.chunk_size = chunk_size\n",
    "        self._num_channels = 1\n",
    "        self._buff = queue.Queue()\n",
    "        self.closed = True\n",
    "        self.start_time = get_current_time()\n",
    "        self.restart_counter = 0\n",
    "        self.audio_input = []\n",
    "        self.last_audio_input = []\n",
    "        self.result_end_time = 0\n",
    "        self.is_final_end_time = 0\n",
    "        self.final_request_end_time = 0\n",
    "        self.bridging_offset = 0\n",
    "        self.last_transcript_was_final = False\n",
    "        self.new_stream = True\n",
    "        self._audio_interface = pyaudio.PyAudio()\n",
    "        self._audio_stream = self._audio_interface.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            channels=self._num_channels,\n",
    "            rate=self._rate,\n",
    "            input=True,\n",
    "            frames_per_buffer=self.chunk_size,\n",
    "            # Run the audio stream asynchronously to fill the buffer object.\n",
    "            # This is necessary so that the input device's buffer doesn't\n",
    "            # overflow while the calling thread makes network requests, etc.\n",
    "            stream_callback=self._fill_buffer,\n",
    "        )\n",
    "\n",
    "    def __enter__(self):\n",
    "\n",
    "        self.closed = False\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "\n",
    "        self._audio_stream.stop_stream()\n",
    "        self._audio_stream.close()\n",
    "        self.closed = True\n",
    "        # Signal the generator to terminate so that the client's\n",
    "        # streaming_recognize method will not block the process termination.\n",
    "        self._buff.put(None)\n",
    "        self._audio_interface.terminate()\n",
    "\n",
    "    def _fill_buffer(self, in_data, *args, **kwargs):\n",
    "        \"\"\"Continuously collect data from the audio stream, into the buffer.\"\"\"\n",
    "\n",
    "        self._buff.put(in_data)\n",
    "        return None, pyaudio.paContinue\n",
    "\n",
    "    def generator(self):\n",
    "        \"\"\"Stream Audio from microphone to API and to local buffer\"\"\"\n",
    "\n",
    "        while not self.closed:\n",
    "            data = []\n",
    "\n",
    "            if self.new_stream and self.last_audio_input:\n",
    "\n",
    "                chunk_time = STREAMING_LIMIT / len(self.last_audio_input)\n",
    "\n",
    "                if chunk_time != 0:\n",
    "\n",
    "                    if self.bridging_offset < 0:\n",
    "                        self.bridging_offset = 0\n",
    "\n",
    "                    if self.bridging_offset > self.final_request_end_time:\n",
    "                        self.bridging_offset = self.final_request_end_time\n",
    "\n",
    "                    chunks_from_ms = round(\n",
    "                        (self.final_request_end_time - self.bridging_offset)\n",
    "                        / chunk_time\n",
    "                    )\n",
    "\n",
    "                    self.bridging_offset = round(\n",
    "                        (len(self.last_audio_input) - chunks_from_ms) * chunk_time\n",
    "                    )\n",
    "\n",
    "                    for i in range(chunks_from_ms, len(self.last_audio_input)):\n",
    "                        data.append(self.last_audio_input[i])\n",
    "\n",
    "                self.new_stream = False\n",
    "\n",
    "            # Use a blocking get() to ensure there's at least one chunk of\n",
    "            # data, and stop iteration if the chunk is None, indicating the\n",
    "            # end of the audio stream.\n",
    "            chunk = self._buff.get()\n",
    "            self.audio_input.append(chunk)\n",
    "\n",
    "            if chunk is None:\n",
    "                return\n",
    "            data.append(chunk)\n",
    "            # Now consume whatever other data's still buffered.\n",
    "            while True:\n",
    "                try:\n",
    "                    chunk = self._buff.get(block=False)\n",
    "\n",
    "                    if chunk is None:\n",
    "                        return\n",
    "                    data.append(chunk)\n",
    "                    self.audio_input.append(chunk)\n",
    "\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "\n",
    "            yield b\"\".join(data)\n",
    "\n",
    "\n",
    "def listen_print_loop(responses, stream):\n",
    "    \"\"\"Iterates through server responses and prints them.\n",
    "    The responses passed is a generator that will block until a response\n",
    "    is provided by the server.\n",
    "    Each response may contain multiple results, and each result may contain\n",
    "    multiple alternatives; for details, see https://goo.gl/tjCPAU.  Here we\n",
    "    print only the transcription for the top alternative of the top result.\n",
    "    In this case, responses are provided for interim results as well. If the\n",
    "    response is an interim one, print a line feed at the end of it, to allow\n",
    "    the next result to overwrite it, until the response is a final one. For the\n",
    "    final one, print a newline to preserve the finalized transcription.\n",
    "    \"\"\"\n",
    "\n",
    "    for response in responses:\n",
    "\n",
    "        if get_current_time() - stream.start_time > STREAMING_LIMIT:\n",
    "            stream.start_time = get_current_time()\n",
    "            break\n",
    "\n",
    "        if not response.results:\n",
    "            continue\n",
    "\n",
    "        result = response.results[0]\n",
    "\n",
    "        if not result.alternatives:\n",
    "            continue\n",
    "\n",
    "        transcript = result.alternatives[0].transcript\n",
    "\n",
    "        result_seconds = 0\n",
    "        result_micros = 0\n",
    "\n",
    "        if result.result_end_time.seconds:\n",
    "            result_seconds = result.result_end_time.seconds\n",
    "\n",
    "        if result.result_end_time.microseconds:\n",
    "            result_micros = result.result_end_time.microseconds\n",
    "\n",
    "        stream.result_end_time = int((result_seconds * 1000) + (result_micros / 1000))\n",
    "\n",
    "        corrected_time = (\n",
    "            stream.result_end_time\n",
    "            - stream.bridging_offset\n",
    "            + (STREAMING_LIMIT * stream.restart_counter)\n",
    "        )\n",
    "        # Display interim results, but with a carriage return at the end of the\n",
    "        # line, so subsequent lines will overwrite them.\n",
    "\n",
    "        if result.is_final:\n",
    "\n",
    "            sys.stdout.write(GREEN)\n",
    "            sys.stdout.write(\"\\033[K\")\n",
    "            sys.stdout.write(str(corrected_time) + \": \" + transcript + \"\\n\")\n",
    "\n",
    "            stream.is_final_end_time = stream.result_end_time\n",
    "            stream.last_transcript_was_final = True\n",
    "\n",
    "            # Exit recognition if any of the transcribed phrases could be\n",
    "            # one of our keywords.\n",
    "            if re.search(r\"\\b(exit|quit)\\b\", transcript, re.I):\n",
    "                sys.stdout.write(YELLOW)\n",
    "                sys.stdout.write(\"Exiting...\\n\")\n",
    "                stream.closed = True\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            sys.stdout.write(RED)\n",
    "            sys.stdout.write(\"\\033[K\")\n",
    "            sys.stdout.write(str(corrected_time) + \": \" + transcript + \"\\r\")\n",
    "\n",
    "            stream.last_transcript_was_final = False\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"start bidirectional streaming from microphone input to speech API\"\"\"\n",
    "    \n",
    "    # our edits\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = 'client_key.json'\n",
    "\n",
    "    client = speech.SpeechClient()\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=SAMPLE_RATE,\n",
    "        model='phone_call',\n",
    "        language_code=\"en-US\",\n",
    "        max_alternatives=1,\n",
    "    )\n",
    "\n",
    "    streaming_config = speech.StreamingRecognitionConfig(\n",
    "        config=config, interim_results=True\n",
    "    )\n",
    "\n",
    "    mic_manager = ResumableMicrophoneStream(SAMPLE_RATE, CHUNK_SIZE)\n",
    "    print(mic_manager.chunk_size)\n",
    "    sys.stdout.write(YELLOW)\n",
    "    sys.stdout.write('\\nListening, say \"Quit\" or \"Exit\" to stop.\\n\\n')\n",
    "    sys.stdout.write(\"End (ms)       Transcript Results/Status\\n\")\n",
    "    sys.stdout.write(\"=====================================================\\n\")\n",
    "\n",
    "    with mic_manager as stream:\n",
    "\n",
    "        while not stream.closed:\n",
    "            sys.stdout.write(YELLOW)\n",
    "            sys.stdout.write(\n",
    "                \"\\n\" + str(STREAMING_LIMIT * stream.restart_counter) + \": NEW REQUEST\\n\"\n",
    "            )\n",
    "\n",
    "            stream.audio_input = []\n",
    "            audio_generator = stream.generator()\n",
    "\n",
    "            requests = (\n",
    "                speech.StreamingRecognizeRequest(audio_content=content)\n",
    "                for content in audio_generator\n",
    "            )\n",
    "\n",
    "            responses = client.streaming_recognize(streaming_config, requests)\n",
    "\n",
    "            # Now, put the transcription responses to use.\n",
    "            listen_print_loop(responses, stream)\n",
    "\n",
    "            if stream.result_end_time > 0:\n",
    "                stream.final_request_end_time = stream.is_final_end_time\n",
    "            stream.result_end_time = 0\n",
    "            stream.last_audio_input = []\n",
    "            stream.last_audio_input = stream.audio_input\n",
    "            stream.audio_input = []\n",
    "            stream.restart_counter = stream.restart_counter + 1\n",
    "\n",
    "            if not stream.last_transcript_was_final:\n",
    "                sys.stdout.write(\"\\n\")\n",
    "            stream.new_stream = True\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
